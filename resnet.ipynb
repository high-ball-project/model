{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd057107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.resnet_v2 import ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c089e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndi\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1318fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 로드\n",
    "image_path = './open/train_imgs/BC_01_0062.png'  # 분할할 이미지 파일 경로\n",
    "image = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cb63e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_masked_image(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    _, a, _ = cv2.split(lab)\n",
    "    th = cv2.threshold(\n",
    "        a, 127, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    mask = np.zeros_like(a)\n",
    "    mask[a < th] = 1\n",
    "    mask[a >= th] = 2\n",
    "    mask = ndi.binary_fill_holes(mask-1)\n",
    "\n",
    "    masked_image = np.zeros_like(image)\n",
    "    masked_image[mask == 1] = image[np.where(mask == 1)]\n",
    "    masked_image[mask == 0] = 255.\n",
    "\n",
    "    return masked_image\n",
    "def _crop_image(image):\n",
    "    for w_pos in reversed(range(image.shape[1])):\n",
    "        if (image[:, w_pos] == [255, 255, 255]).all():\n",
    "            image = np.delete(image, w_pos, 1)\n",
    "    for h_pos in reversed(range(image.shape[0])):\n",
    "        if (image[h_pos, :] == [255, 255, 255]).all():\n",
    "            image = np.delete(image, h_pos, 0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ede6af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_image(image, tile_size, n_tiles):\n",
    "    h, w, ch = image.shape\n",
    "\n",
    "    pad_h, pad_w = (\n",
    "        tile_size - h % tile_size) % tile_size, (tile_size - w % tile_size) % tile_size\n",
    "    padding = [[pad_h//2, pad_h-pad_h//2],\n",
    "               [pad_w//2, pad_w-pad_w//2], [0, 0]]\n",
    "    image = np.pad(image, padding, mode='constant', constant_values=255)\n",
    "\n",
    "    image = image.reshape(\n",
    "        image.shape[0]//tile_size, tile_size, image.shape[1]//tile_size, tile_size, ch)\n",
    "    tiles = image.transpose(\n",
    "        0, 2, 1, 3, 4).reshape(-1, tile_size, tile_size, ch)\n",
    "\n",
    "    if len(tiles) < n_tiles:\n",
    "        padding = [[0, n_tiles-len(tiles)], [0, 0], [0, 0], [0, 0]]\n",
    "        tiles = np.pad(tiles, padding, mode='constant', constant_values=255)\n",
    "\n",
    "    idxs = np.argsort(tiles.reshape(tiles.shape[0], -1).sum(-1))[:n_tiles]\n",
    "    tiles = tiles[idxs]\n",
    "\n",
    "    return tiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b7de0",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5e757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = _get_masked_image(image)\n",
    "# scale_percent = 20\n",
    "\n",
    "# # 축소할 크기 계산\n",
    "# width = int(image1.shape[1] * scale_percent / 100)\n",
    "# height = int(image1.shape[0] * scale_percent / 100)\n",
    "\n",
    "# # 이미지 축소\n",
    "# resized_image1 = cv2.resize(image1, (width, height))\n",
    "\n",
    "# 이미지 출력\n",
    "cv2.imwrite('Resized Image1.png', image1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# cv2.imshow('Segmentation Result', _get_masked_image(image))\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec13831",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = _get_masked_image(image)\n",
    "crop_2 = _crop_image(image2)\n",
    "\n",
    "# scale_percent = 20\n",
    "\n",
    "# # 축소할 크기 계산\n",
    "# width = int(image2.shape[1] * scale_percent / 100)\n",
    "# height = int(image2.shape[0] * scale_percent / 100)\n",
    "\n",
    "# # 이미지 축소\n",
    "# resized_image2 = cv2.resize(image2, (width, height))\n",
    "\n",
    "# 이미지 출력\n",
    "cv2.imwrite('Resized Image2.png', crop_2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# cv2.imshow('Segmentation Result', _get_masked_image(image))\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "801445bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 너비: 5981\n",
      "이미지 높이: 2309\n"
     ]
    }
   ],
   "source": [
    "height, width, _ = crop_2.shape\n",
    "# 너비와 높이 출력\n",
    "print(\"이미지 너비:\", width)\n",
    "print(\"이미지 높이:\", height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b79f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.308035714285714"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2309 / 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a123286",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = tile_image(crop_2, 224, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d54ca644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_dir = './test_tiles'\n",
    "file_prefix = 'test_tile'\n",
    "\n",
    "# 타일 이미지 저장\n",
    "for i, tile in enumerate(tiles):\n",
    "    file_name = f'{file_prefix}{i}.png'\n",
    "    file_path = os.path.join(save_dir, file_name)\n",
    "    cv2.imwrite(file_path, tile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f746fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/lim-hyo-jeong/DACON-Breast-Cancer/blob/master/image_preprocessing.py\n",
    "#참고해서 나누고 학습 진행 후 앙상블까지 끝내보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd78a8",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b93b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_masked_image(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    _, a, _ = cv2.split(lab)\n",
    "    th = cv2.threshold(\n",
    "        a, 127, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    mask = np.zeros_like(a)\n",
    "    mask[a < th] = 1\n",
    "    mask[a >= th] = 2\n",
    "    mask = ndi.binary_fill_holes(mask-1)\n",
    "\n",
    "    masked_image = np.zeros_like(image)\n",
    "    masked_image[mask == 1] = image[np.where(mask == 1)]\n",
    "    masked_image[mask == 0] = 255.\n",
    "\n",
    "    return masked_image\n",
    "\n",
    "def _crop_image(image):\n",
    "    for w_pos in reversed(range(image.shape[1])):\n",
    "        if (image[:, w_pos] == [255, 255, 255]).all():\n",
    "            image = np.delete(image, w_pos, 1)\n",
    "    for h_pos in reversed(range(image.shape[0])):\n",
    "        if (image[h_pos, :] == [255, 255, 255]).all():\n",
    "            image = np.delete(image, h_pos, 0)\n",
    "\n",
    "    return image\n",
    "\n",
    "def tile_image(image, tile_size, n_tiles):\n",
    "    h, w, ch = image.shape\n",
    "\n",
    "    pad_h, pad_w = (\n",
    "        tile_size - h % tile_size) % tile_size, (tile_size - w % tile_size) % tile_size\n",
    "    padding = [[pad_h//2, pad_h-pad_h//2],\n",
    "               [pad_w//2, pad_w-pad_w//2], [0, 0]]\n",
    "    image = np.pad(image, padding, mode='constant', constant_values=255)\n",
    "\n",
    "    image = image.reshape(\n",
    "        image.shape[0]//tile_size, tile_size, image.shape[1]//tile_size, tile_size, ch)\n",
    "    tiles = image.transpose(\n",
    "        0, 2, 1, 3, 4).reshape(-1, tile_size, tile_size, ch)\n",
    "\n",
    "    if len(tiles) < n_tiles:\n",
    "        padding = [[0, n_tiles-len(tiles)], [0, 0], [0, 0], [0, 0]]\n",
    "        tiles = np.pad(tiles, padding, mode='constant', constant_values=255)\n",
    "\n",
    "    idxs = np.argsort(tiles.reshape(tiles.shape[0], -1).sum(-1))[:n_tiles]\n",
    "    tiles = tiles[idxs]\n",
    "\n",
    "    return tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5599329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 여백제거\n",
    "\n",
    "# image_path = './open/train_imgs/'  # 분할할 이미지 파일 경로\n",
    "# save_path = './open/lab_train/'\n",
    "# file_list = os.listdir(image_path)\n",
    "\n",
    "# # 파일 목록 출력\n",
    "# for file_name in file_list:\n",
    "#     image = cv2.imread(image_path+file_name)\n",
    "#     image2 = _get_masked_image(image)\n",
    "#     crop_2 = _crop_image(image2)\n",
    "#     file_path = os.path.join(save_path, file_name)\n",
    "#     cv2.imwrite(file_path, crop_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aaddb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>N_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BC_01_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BC_01_0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BC_01_0003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BC_01_0004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BC_01_0005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>BC_01_3464</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>BC_01_3482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>BC_01_3485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>BC_01_3502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>BC_01_3518</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  N_category\n",
       "0    BC_01_0001           0\n",
       "1    BC_01_0002           1\n",
       "2    BC_01_0003           0\n",
       "3    BC_01_0004           0\n",
       "4    BC_01_0005           0\n",
       "..          ...         ...\n",
       "995  BC_01_3464           1\n",
       "996  BC_01_3482           0\n",
       "997  BC_01_3485           1\n",
       "998  BC_01_3502           0\n",
       "999  BC_01_3518           1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#일단 타뷸러 데이터 불러오기\n",
    "df =  pd.read_csv(\"./open/train.csv\")\n",
    "answer = df[[\"ID\",\"N_category\"]]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5d4887ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer[\"N_category\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a12a6986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tiles = tile_image(crop_2, 224, 16)\n",
    "# image_path = './open/lab_train/'  # 분할할 이미지 파일 경로\n",
    "# file_list = os.listdir(image_path)\n",
    "# cancer_dir = './open/data/cancer'\n",
    "# cancer_prefix = 'cancer'\n",
    "# normal_dir = './open/data/normal'\n",
    "# normal_prefix = 'normal'\n",
    "# for i, file_name in enumerate(file_list):\n",
    "#     image = cv2.imread(image_path+file_name)\n",
    "#     if(answer[\"N_category\"][i] == 0):\n",
    "#         tiles = tile_image(image, 224, 16)\n",
    "#         for i, tile in enumerate(tiles):\n",
    "#             file_path = os.path.join(normal_dir, file_name+f'_{normal_prefix}{i}.png')\n",
    "#             cv2.imwrite(file_path, tile)\n",
    "#     else:\n",
    "#         tiles = tile_image(image, 224, 16)\n",
    "#         for i, tile in enumerate(tiles):\n",
    "#             file_path = os.path.join(cancer_dir, file_name+f'_{cancer_prefix}{i}.png')\n",
    "#             cv2.imwrite(file_path, tile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80f7bf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 16000 files [01:58, 135.44 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "# train/val/test 나누기\n",
    "# ratio 파라미터에 원하는 (train, validation, test) 비율을 입력합니다. ex) (0.8, 0.1, 0.1)\n",
    "splitfolders.ratio(\"./open/data\", output=\"output\", seed=42, ratio=(.7, .2, .1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d5c78",
   "metadata": {},
   "source": [
    "## 데이터 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad3eb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11199 images belonging to 2 classes.\n",
      "Found 3199 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "training_dir = './output/train/'\n",
    "validation_dir = './output/val/'\n",
    "\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    batch_size=16,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=16,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='binary'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdbc9de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 29\u001b[0m\n\u001b[0;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     25\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     26\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 모델 평가\u001b[39;00m\n\u001b[0;32m     34\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m  \u001b[38;5;66;03m# 테스트 데이터셋 로드\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\test2\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\test2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\test2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\test2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\test2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\test2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\test2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\test2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 데이터 준비\n",
    "# train_dataset = './output/train/'\n",
    "# valid_dataset = './output/val/'\n",
    "train_dataset = train_generator\n",
    "valid_dataset = validation_generator\n",
    "# ResNet 모델 생성\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(train_dataset,\n",
    "          validation_data=valid_dataset,\n",
    "          epochs=100,verbose=2)\n",
    "\n",
    "# 모델 평가\n",
    "test_dataset = ...  # 테스트 데이터셋 로드\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이미지 데이터와 암 여부를 나타내는 레이블 데이터가 있다고 가정\n",
    "# X = 이미지 데이터\n",
    "# y = 암 여부 레이블 데이터\n",
    "\n",
    "# # 암에 걸린 이미지와 안걸린 이미지로 나눔\n",
    "# X_cancer = X[y == 1]  # 암에 걸린 이미지\n",
    "# X_normal = X[y == 0]  # 안걸린 이미지\n",
    "\n",
    "# # 암에 걸린 이미지와 안걸린 이미지를 각각 학습 세트와 테스트 세트로 나눔\n",
    "# X_cancer_train, X_cancer_test = train_test_split(X_cancer, test_size=0.2, random_state=42)\n",
    "# X_normal_train, X_normal_test = train_test_split(X_normal, test_size=0.2, random_state=42)\n",
    "\n",
    "# # 학습 세트에는 암과 안걸린 이미지가 모두 포함되도록 합침\n",
    "# X_train = np.concatenate([X_cancer_train, X_normal_train], axis=0)\n",
    "\n",
    "# # 테스트 세트에는 암과 안걸린 이미지가 모두 포함되도록 합침\n",
    "# X_test = np.concatenate([X_cancer_test, X_normal_test], axis=0)\n",
    "\n",
    "# # 각각의 이미지에 대한 레이블을 생성\n",
    "# y_train = np.concatenate([np.ones(X_cancer_train.shape[0]), np.zeros(X_normal_train.shape[0])], axis=0)\n",
    "# y_test = np.concatenate([np.ones(X_cancer_test.shape[0]), np.zeros(X_normal_test.shape[0])], axis=0)\n",
    "\n",
    "# # 데이터 세트 확인\n",
    "# print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
    "# print(\"Test set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77acae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd825e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2cd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test2",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
